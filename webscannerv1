import urllib.request
from urllib.error import URLError, HTTPError
from bs4 import BeautifulSoup
from datetime import datetime
import re

def extract_relevant_text(html_content):
    """Extract text following 'Tagged:' or 'Doc ID:' and clean it from HTML tags."""
    soup = BeautifulSoup(html_content, 'html.parser')
    text = soup.get_text()
    patterns = [r"Tagged:\s*(.*?)\s*(?:$|\n)", r"Doc ID:\s*(.*?)\s*(?:$|\n)"]
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            return match.group(1).strip()
    return "No Value found"

def format_url(url):
    """Ensure the URL includes the HTTP/HTTPS protocol."""
    if not url.startswith(('http://', 'https://')):
        return 'http://' + url
    return url

def main():
    input_filename = "input.txt"
    output_filename = f"documentrepo_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    
    try:
        with open(input_filename, 'r') as file:
            urls = [format_url(url.strip()) for url in file.readlines()]
    except FileNotFoundError:
        print(f"Error: The file '{input_filename}' does not exist.")
        return
    
    with open(output_filename, 'w') as outfile:
        for url in urls:
            try:
                response = urllib.request.urlopen(url)
                html_content = response.read()
                extracted_text = extract_relevant_text(html_content.decode('utf-8'))
            except (HTTPError, URLError) as e:
                print(f"Failed to fetch {url}: {e}")
                extracted_text = "Invalid URL"
            except Exception as e:
                print(f"An unexpected error occurred with {url}: {e}")
                extracted_text = "Error processing URL"
            
            outfile.write(f"{url} | {extracted_text}\n")

if __name__ == "__main__":
    main()
